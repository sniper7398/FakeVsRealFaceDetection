# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/107bySdAGqeWucuH-Q--1vM3lyLuvBV43
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow-gpu==2.0.0-alpha
!pip install split-folders

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import GlobalAveragePooling2D
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dropout
from tensorflow.keras.layers import Dense
from tensorflow.keras import Sequential
import matplotlib.pyplot as plt
import tensorflow as tf
import split_folders
import numpy as np
import cv2
import os

real = "/content/drive/My Drive/real-and-fake-face-detection/real_and_fake_face/training_real"
fake = "/content/drive/My Drive/real-and-fake-face-detection/real_and_fake_face/training_fake"

real_path = os.listdir(real)
fake_path = os.listdir(fake)

def load_img(path):
    image = cv2.imread(path)
    image = cv2.resize(image, (224, 224))
    return image[...,::-1]

train_datagen = ImageDataGenerator(horizontal_flip=True,
                                   vertical_flip=False,
                                   rescale=1./255,
                                   )

dataset_path = "/content/drive/My Drive/real-and-fake-face-detection/real_and_fake_face"

train = train_datagen.flow_from_directory(dataset_path,
                                          class_mode="binary",
                                          target_size=(96, 96),
                                          batch_size=32)

x, y = next(train)



ResNet = ResNet50(input_shape=(96, 96, 3),
                          include_top=False,
                          weights='imagenet'
                          )

average_layer = GlobalAveragePooling2D()

model = Sequential([
    ResNet,
    average_layer,
    Dense(256, activation=tf.nn.relu),
    BatchNormalization(),
    Dropout(0.2),
    Dense(2, activation=tf.nn.softmax)
])

model.summary()

model.compile(optimizer=Adam(lr=0.001),
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

def scheduler(epoch):
    if epoch <= 2:
        return 0.001
    elif epoch > 2 and epoch <= 15:
        return 0.0001 
    else:
        return 0.00001

lr_callbacks = tf.keras.callbacks.LearningRateScheduler(scheduler)

# from keras.models import load_model
# model = load_model('model.h5')

model.fit_generator(train,
                    epochs=50,
                    callbacks=[lr_callbacks])

model.save("model.h5")

model.evaluate_generator(train)

model.predict_generator(train)